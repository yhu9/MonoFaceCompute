import argparse
import logging
import os
import time
from pathlib import Path
from typing import Dict, List
import torch
import yaml

from compute.utils import DotDict, run_cmd, run_cmds, setup_logging

DEFAULT_FOCAL_LENGTH = 1200
MAX_THREADS = 0  # set to 0 to disable multithreading

PATH_ROOT = Path("./").absolute()
PATH_MODNET = PATH_ROOT / "submodules/MODNet"
PATH_FACE_PARSING = PATH_ROOT / "submodules/face-parsing.PyTorch"
PATH_INFERNO = PATH_ROOT / "submodules/INFERNO"
PATH_SMIRK = PATH_ROOT / "submodules/SMIRK"
PATH_OMNIDATA = PATH_ROOT / "submodules/omnidata"
PATH_DSINE = PATH_ROOT / "submodules/DSINE/projects/dsine"

NORMALS_ESTIMATOR = "dsine"  # omnidata | dsine
torch.set_grad_enabled(False)

def title(s: str) -> str:
    """Return a formatted title string."""
    return "\n" + "#" * 50 + f"\n{s}\n" + "#" * 50


def run(
    sequences: Dict,
    shape_sequence: str,
    output_dir: str,
    resize: int,
    crop_scale: float,
    crop_mode: str,
    smooth_tracking: bool,
    tracker: str,
    shape_tracker: str,
    steps: List[str]
) -> None:
    """Run the processing pipeline."""
    setup_logging()

    if MAX_THREADS > 0:
        num_threads = min(len(sequences), 4)
    else:
        num_threads = 0

    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True, parents=True)

    seq_dirs = {}
    frame_patterns: Dict[str, Path] = {}
    crop_patterns: Dict[str, Path] = {}
    mask_patterns: Dict[str, Path] = {}
    deca_dirs: Dict[str, Path] = {}
    segmentation_dirs: Dict[str, Path] = {}
    normals_dirs: Dict[str, Path] = {}

    for seq_name in sequences:
        seq_dir = output_path / str(seq_name)
        seq_dirs[seq_name] = seq_dir
        frame_patterns[seq_name] = seq_dir / "image" / "%d.png"
        crop_patterns[seq_name] = seq_dir / "crops" / "%d.png"
        mask_patterns[seq_name] = seq_dir / "mask" / "%d.png"
        deca_dirs[seq_name] = seq_dir / "deca"
        segmentation_dirs[seq_name] = seq_dir / "semantic"
        normals_dirs[seq_name] = seq_dir / "normals"

    start_time = time.time()

    ############################################################
    if "extract" in steps:
        logging.info(title("Extract, crop and resize frames"))
        cmds = []
        for seq_name, seq in sequences.items():
            source = seq["source"]
            frame_patterns[seq_name].parent.mkdir(exist_ok=True, parents=True)
            cmd = (
                f"ffmpeg -y {'-pattern_type glob' if '*' in source else ''} -i '{source}'"
                f" -vf 'mpdecimate, setpts=N/FRAME_RATE/TB'"
                f" '{frame_patterns[seq_name]}'"
            )
            cmds.append(cmd)
        run_cmds(cmds, num_threads)

    ############################################################
    if "crop" in steps:
        logging.info(title("Detect & crop faces"))
        cmds = []
        for seq_name, seq in sequences.items():
            segmentation_dirs[seq_name].mkdir(exist_ok=True, parents=True)
            cmd = (
                f"python compute/detect_crops.py --batch_size 8 --resize {resize} --scale {crop_scale} "
                f"--input '{frame_patterns[seq_name].parent}' --output '{crop_patterns[seq_name].parent}'"
            )
            cmd += (
                f" --mode {seq.crop_mode if 'crop_mode' in seq else crop_mode}"
                + (f" --fixed_box {' '.join(map(str, seq.fixed_box))}" if "fixed_box" in seq else "")
                + f" --face_selection_strategy {seq.face_selection_strategy}"
            )
            cmds.append(cmd)
        run_cmds(cmds, cwd=PATH_ROOT)

    ############################################################
    if "matte" in steps:
        logging.info(title("Matting (background/foreground segmentation)"))
        cmds = []
        for seq_name, seq in sequences.items():
            mask_patterns[seq_name].parent.mkdir(exist_ok=True, parents=True)
            cmd = (
                f"python -m demo.image_matting.colab.inference --input-path '{crop_patterns[seq_name].parent}'"
                f" --output-path '{mask_patterns[seq_name].parent}' --ckpt-path ./pretrained/modnet_webcam_portrait_matting.ckpt"
            )
            cmds.append(cmd)
        run_cmds(cmds, num_threads, cwd=PATH_MODNET)

    ############################################################
    if "segment" in steps:
        logging.info(title("Semantic face segmentation"))
        cmds = []
        for seq_name, seq in sequences.items():
            segmentation_dirs[seq_name].mkdir(exist_ok=True, parents=True)
            cmd = (
                f"python test.py --input_dir '{crop_patterns[seq_name].parent}' --output_dir '{segmentation_dirs[seq_name]}'"
            )
            cmds.append(cmd)
        run_cmds(cmds, cwd=PATH_FACE_PARSING)

    ############################################################
    if "normals" in steps:
        assert NORMALS_ESTIMATOR in ["omnidata", "dsine"]

        logging.info(title("Normals estimation"))
        cmds = []
        for seq_name, seq in sequences.items():
            normals_dirs[seq_name].mkdir(exist_ok=True, parents=True)

            if NORMALS_ESTIMATOR == "omnidata":
                cmd = (
                    f"python estimate_normals.py --task normal --img_path '{crop_patterns[seq_name].parent}'"
                    f" --output_path '{normals_dirs[seq_name]}'"
                )
            elif NORMALS_ESTIMATOR == "dsine":
                cmd = (
                    f"python test_minimal_custom.py ./experiments/exp001_cvpr2024/dsine.txt"
                    f" --input_dir '{crop_patterns[seq_name].parent}' --output_dir '{normals_dirs[seq_name]}'"
                )
            cmds.append(cmd)
        run_cmds(cmds, cwd={"omnidata": PATH_OMNIDATA, "dsine": PATH_DSINE}[NORMALS_ESTIMATOR])

    ############################################################
    if "landmarks" in steps:
        logging.info(title("Landmarks detection"))
        cmds = []
        for seq_name, seq in sequences.items():
            cmd = (
                f"python compute/detect_landmarks.py --images '{str(crop_patterns[seq_name]).replace('%d', '*')}'"
                f" --output_dir '{seq_dirs[seq_name]}'"
            )
            cmds.append(cmd)
        run_cmds(cmds, num_threads, cwd=PATH_ROOT)

    # All the remaining steps run on GPU, so we don't do multi-threading for those

    ############################################################
    if "track" in steps:
        logging.info(title(f"FLAME parameter estimation using tracker `{tracker}`"))

        def track(tracker_name: str, seq_name: str, output_name: str) -> str:
            if tracker_name == "DECA":
                cmd = (
                    f"python inferno_apps/EMOCA/demos/test_emoca_on_images.py --input_folder '{crop_patterns[seq_name].parent}'"
                    f" --output_folder '{seq_dirs[seq_name]}' --save_codes True --save_images False"
                    f" --model_name DECA --batch_size 16 --output_name {output_name}"
                )
            elif tracker_name == "EMOCA":
                cmd = (
                    f"python inferno_apps/EMOCA/demos/test_emoca_on_images.py --input_folder '{crop_patterns[seq_name].parent}'"
                    f" --output_folder '{seq_dirs[seq_name]}' --save_codes True --save_images False"
                    f" --model_name EMOCA_v2_lr_mse_20 --batch_size 16 --output_name {output_name}"
                )
            elif tracker_name == "FaceReconstruction":
                cmd = (
                    f"python inferno_apps/FaceReconstruction/demo/demo_face_rec_on_images.py --input_folder '{crop_patterns[seq_name].parent}'"
                    f" --output_folder '{seq_dirs[seq_name]}' --save_codes True --save_images False"
                    f" --batch_size 16 --output_name {output_name}"
                )
            elif tracker_name == "SMIRK":
                cmd = (
                    f"python demo_images.py --input_folder '{crop_patterns[seq_name].parent}'"
                    f" --output_folder '{seq_dirs[seq_name]}' --batch_size 16 --output_name {output_name}"
                )
                cmd = f"PYTHONPATH={PATH_SMIRK} {cmd}"
            else:
                raise ValueError(f"Unknown tracker '{tracker_name}'")
            return cmd

        cmds = [
            track(tracker, seq_name, "flame_params_inferred.json")
            for seq_name in sequences.keys()
        ]
        run_cmds(cmds, cwd=PATH_SMIRK if tracker == "SMIRK" else PATH_INFERNO)

        # If shape_tracker is different, track the shape sequence again using that tracker
        if shape_tracker != tracker:
            run_cmd(
                track(shape_tracker, shape_sequence, "flame_params_inferred_shape.json"),
                cwd=PATH_SMIRK if shape_tracker == "SMIRK" else PATH_INFERNO,
            )

    ############################################################
    if "optimize" in steps:
        cx = resize / 2
        cy = resize / 2

        # Run optimization with 0 iters just to convert the inferred shape from shape_tracker to the same format
        if shape_tracker != tracker:
            cmd = (
                f"python compute/optimize.py --path '{seq_dirs[shape_sequence]}' --size {resize} --iterations 0"
                f" --input_name flame_params_inferred_shape.json --save_name flame_params_optimized_shape"
            )
            run_cmd(cmd, cwd=PATH_ROOT)

        logging.info(title(f"Fit FLAME parameter for one video: {shape_sequence}"))
        fl = sequences[shape_sequence].get("fl", DEFAULT_FOCAL_LENGTH)
        cmd = (
            f"python compute/optimize.py --path '{seq_dirs[shape_sequence]}' --input_name flame_params_inferred.json"
            f" --cx {cx} --cy {cy} --fx {fl} --fy {fl} --size {resize}"
            f" {'--smooth' if smooth_tracking else ''} --optimize_shape"
        )
        if shape_tracker != tracker:
            cmd += f" --shape_from '{seq_dirs[shape_sequence] / 'flame_params_optimized_shape.json'}'"
        run_cmd(cmd, cwd=PATH_ROOT)

        logging.info(title("Fit FLAME parameter for other videos, while keeping shape parameter fixed"))
        cmds = []
        for seq_name, seq in sequences.items():
            if seq_name == shape_sequence:
                continue
            fl = seq.get("fl", DEFAULT_FOCAL_LENGTH)
            cmd = (
                f"python compute/optimize.py --path '{seq_dirs[seq_name]}'"
                f" --shape_from '{seq_dirs[shape_sequence] / 'flame_params_optimized.json'}'"
                f" --cx {cx} --cy {cy} --fx {fl} --fy {fl} --size {resize}"
                f" {'--smooth' if smooth_tracking else ''}"
            )
            cmds.append(cmd)
        run_cmds(cmds, cwd=PATH_ROOT)

    end_time = time.time()
    logging.info(f"Done! Time taken: {time.strftime('%H:%M:%S', time.gmtime(end_time - start_time))}")

    if "visualize" in steps:
        logging.info(title("Visualize tracking"))
        cmds = []
        for seq_name, seq in sequences.items():
            cmd = (
                f"python compute/visualize.py --path '{seq_dirs[seq_name]}'"
                f" --tracking_name flame_params_optimized.json"
                f" --output_dir '{seq_dirs[seq_name]}/visualize'"
            )
            cmds.append(cmd)
        run_cmds(cmds, cwd=PATH_ROOT)
    end_time = time.time()
    logging.info(f"Done! Time taken: {time.strftime('%H:%M:%S', time.gmtime(end_time - start_time))}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", type=str, help="YAML configuration file.")
    args = parser.parse_args()

    if not os.path.exists(args.dataset):
        raise ValueError(f"Provided dataset '{args.dataset}' not found.")

    with open(args.dataset, "r") as file:
        cfg = yaml.safe_load(file)
    cfg = DotDict(cfg)

    # Set defaults
    if "steps" not in cfg:
        cfg.steps = ["extract", "crop", "matte", "segment", "landmarks", "track", "optimize"]
    if "tracker" not in cfg:
        cfg.tracker = "EMOCA"
    if "shape_tracker" not in cfg:
        cfg.shape_tracker = cfg.tracker
    if "smooth_tracking" not in cfg:
        cfg.smooth_tracking = True
    for seq in cfg.sequences.values():
        if "face_selection_strategy" not in seq:
            seq.face_selection_strategy = "max_confidence"

    if "base_dir" in cfg:
        for seq in cfg.sequences.values():
            seq.source = os.path.join(cfg.base_dir, seq.source)

    run(
        cfg.sequences,
        cfg.shape_sequence,
        cfg.output_dir,
        cfg.resize,
        cfg.crop_scale,
        cfg.crop_mode,
        cfg.smooth_tracking,
        cfg.tracker,
        cfg.shape_tracker,
        cfg.steps,
    )
